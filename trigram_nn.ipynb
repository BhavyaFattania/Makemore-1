{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96c5ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia'] 32033\n"
     ]
    }
   ],
   "source": [
    "words = open(\"names.txt\",\"r\").read().splitlines()\n",
    "print(words[:5],len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630fd6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31970"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for w in words:\n",
    "    if len(w) <=2:\n",
    "    \n",
    "        words.remove(w)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4744a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "sorted_alphabets = sorted(list(set(\"\".join(words))))\n",
    "stoi = {}\n",
    "for i , j in enumerate(sorted_alphabets):\n",
    "    stoi[j] = i+1\n",
    "stoi[\".\"] = 0\n",
    "print(stoi)\n",
    "itos = {}\n",
    "for i , j in enumerate(sorted_alphabets):\n",
    "    itos[i+1] = j\n",
    "itos[0] = \".\"\n",
    "print(itos)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f34fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539b851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.ones(size = (27,27,27))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f718b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for w in words:\n",
    "    \n",
    "    chs = [\".\"] + [\".\"] + list(w) + [\".\"]\n",
    "    \n",
    "    for ch1,ch2,ch3 in zip(chs,chs[1:],chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        N[ix1,ix2,ix3] +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a666a92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11cfd552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to normalize the counts\n",
    "# sum when the dimension is 1\n",
    "sum1 = N.sum(dim=2,keepdim=True)\n",
    "sum1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dee9132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N /= sum1\n",
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915b6862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce\n",
      "bra\n",
      "jalius\n",
      "rochityharlonimittain\n",
      "luwak\n",
      "ka\n",
      "da\n",
      "samiyah\n",
      "javer\n",
      "gotai\n"
     ]
    }
   ],
   "source": [
    "g= torch.Generator().manual_seed(2147483647)\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    numbers = []\n",
    "    ix1=0\n",
    "    ix2=0\n",
    "    while True:\n",
    "        \n",
    "        ix = torch.multinomial(N[ix1,ix2,:],num_samples=1,replacement=True,generator=g).item()\n",
    "        if itos[ix]==\".\":\n",
    "            break\n",
    "        ix1=ix2\n",
    "        ix2=ix\n",
    "        numbers.append(itos[ix])\n",
    "        \n",
    "    print(\"\".join(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b45c3ee",
   "metadata": {},
   "source": [
    "### Loss of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475a7571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative log likelihood of this network is :  2.2112069107331647\n"
     ]
    }
   ],
   "source": [
    "log_prob=0.0\n",
    "n=0\n",
    "for w in words:\n",
    "    chs = [\".\"] + [\".\"] + list(w) + [\".\"]\n",
    "    for ch1,ch2,ch3 in zip(chs,chs[1:],chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        log_prob += torch.log(N[ix1,ix2,ix3])\n",
    "        n+=1\n",
    "print(\"Negative log likelihood of this network is : \", -log_prob.item()/n)     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e214e",
   "metadata": {},
   "source": [
    "## Now we will build the neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96d4b6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([227957])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs,ys = [],[]\n",
    "for w in words:\n",
    "    chs = [\".\"] + [\".\"] + list(w) + [\".\"]\n",
    "    for ch1,ch2,ch3 in zip(chs,chs[1:],chs[2:]):\n",
    "        xs.append([stoi[ch1],stoi[ch2]])\n",
    "        ys.append(stoi[ch3])\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fe629ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) torch.Size([227957, 54])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float().reshape((227957,54))\n",
    "print(xenc[0],xenc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5c052258",
   "metadata": {},
   "outputs": [],
   "source": [
    "g= torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn(size=(54,27),requires_grad=True,generator=g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee6d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0003, 0.1018, 0.0324, 0.0190, 0.0417, 0.0288, 0.0618, 0.2490, 0.0074,\n",
       "        0.1235, 0.0169, 0.0012, 0.0341, 0.0043, 0.0297, 0.0164, 0.0171, 0.0280,\n",
       "        0.0376, 0.0566, 0.0048, 0.0008, 0.0157, 0.0068, 0.0211, 0.0187, 0.0247],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ix=0\n",
    "name = []\n",
    "g= torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(dim=1,keepdim=True)\n",
    "\n",
    "prob.shape\n",
    "prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57f9ad02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2928, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(227957), ys].log().mean() + 0.1 * (W**2).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "158ff9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad = None\n",
    "loss.backward()\n",
    "\n",
    "W.data -=  W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a509b01",
   "metadata": {},
   "source": [
    "### Building the full GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2dbe8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "10 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "20 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "30 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "40 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "50 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "60 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "70 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "80 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "90 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "100 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "110 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "120 tensor(2.3371, grad_fn=<NegBackward0>)\n",
      "130 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "140 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "150 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "160 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "170 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "180 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "190 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "200 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "210 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "220 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "230 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "240 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "250 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "260 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "270 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "280 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "290 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "300 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "310 tensor(2.3370, grad_fn=<NegBackward0>)\n",
      "320 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "330 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "340 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "350 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "360 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "370 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "380 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "390 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "400 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "410 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "420 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "430 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "440 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "450 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "460 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "470 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "480 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "490 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "500 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "510 tensor(2.3369, grad_fn=<NegBackward0>)\n",
      "520 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "530 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "540 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "550 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "560 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "570 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "580 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "590 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "600 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "610 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "620 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "630 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "640 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "650 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "660 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "670 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "680 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "690 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "700 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "710 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "720 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "730 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "740 tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "750 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "760 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "770 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "780 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "790 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "800 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "810 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "820 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "830 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "840 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "850 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "860 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "870 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "880 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "890 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "900 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "910 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "920 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "930 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "940 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "950 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "960 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "970 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "980 tensor(2.3367, grad_fn=<NegBackward0>)\n",
      "990 tensor(2.3367, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    # forward pass\n",
    "    logits = xenc @ W\n",
    "    # Calculate softmax\n",
    "    counts = logits.exp()\n",
    "    prob = counts / counts.sum(dim=1,keepdim=True)\n",
    "\n",
    "    # calculate loss\n",
    "    loss = -prob[torch.arange(227957), ys].log().mean() \n",
    "    if i%10==0:\n",
    "        print(i,loss)\n",
    "    \n",
    "    # backpropogation\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data -=  10* W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c1ad6d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 2])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "w = \"bhavya\"\n",
    "test = []\n",
    "validate = []\n",
    "chs = [\".\"] + [\".\"] + list(w) + [\".\"]\n",
    "for ch1,ch2,ch3 in zip(chs,chs[1:],chs[2:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    ix3 = stoi[ch3]\n",
    "    test.append([ix1,ix2])\n",
    "    validate.append(ix3)\n",
    "\n",
    "test = torch.tensor(test)\n",
    "validate = torch.tensor(validate)\n",
    "print(test.shape)\n",
    "print(validate.shape)\n",
    "n = test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e61f7aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 54])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = F.one_hot(test,num_classes=27).reshape((n,54)).float()\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f17d34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "logits = test_x @ W     # multiply by weights\n",
    "\n",
    "# calculate softmax\n",
    "count = logits.exp()\n",
    "prob = count/count.sum(dim=1,keepdim=True)\n",
    "\n",
    "loss = -prob[torch.arange(n),validate].log().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fd467d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5378, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f734e9",
   "metadata": {},
   "source": [
    "## Final Validation loss is 2.4636 of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "364022f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce.\n",
      "braidallurailazitynnellin.\n",
      "jana.\n",
      "nallayn.\n",
      "ka.\n",
      "da.\n",
      "samiyaubrtthrigotai.\n",
      "morielliaugie.\n",
      "teda.\n",
      "kaleyla.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "    ix1 = 0\n",
    "    ix2 = 0\n",
    "    word = []\n",
    "    while True:\n",
    "        input_data = F.one_hot(torch.tensor([ix1,ix2]),num_classes=27).float().reshape(1,54)\n",
    "        logits = input_data @ W\n",
    "        count = logits.exp()\n",
    "        prob = count/count.sum(dim=1,keepdim=True)\n",
    "        ix = torch.multinomial(prob,num_samples=1,replacement=True,generator=g).item()\n",
    "        word.append(itos[ix])\n",
    "        if ix ==0:\n",
    "            break\n",
    "        ix1 = ix2\n",
    "        ix2 = ix\n",
    "\n",
    "    print(\"\".join(word))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c7ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
