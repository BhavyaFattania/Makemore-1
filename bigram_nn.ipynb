{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c69b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "print(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55e457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements  164080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75de60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements  228146\n",
      "tensor([ 0,  5, 13,  ..., 25, 26, 24])\n"
     ]
    }
   ],
   "source": [
    "xs,ys = [],[]\n",
    "for w in words:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1= stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(\"number of elements \",num)\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "95ac3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "parameters = torch.randn(size=(27,27), generator = g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "63206ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.]) torch.Size([228146, 27])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs,num_classes=27).float()\n",
    "print(xenc[1,:], xenc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bd3cd37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.5674, -0.2373, -0.0274, -1.1008,  0.2859, -0.0296, -1.5471,  0.6049,\n",
      "         0.0791,  0.9046, -0.4713,  0.7868, -0.3284, -0.4330,  1.3729,  2.9334,\n",
      "         1.5618, -1.6261,  0.6772, -0.8404,  0.9849, -0.1484, -1.4795,  0.4483,\n",
      "        -0.0707,  2.4968,  2.4448], grad_fn=<SelectBackward0>) torch.Size([228146, 27])\n",
      "tensor([ 4.7940,  0.7888,  0.9730,  0.3326,  1.3309,  0.9708,  0.2129,  1.8311,\n",
      "         1.0824,  2.4710,  0.6242,  2.1964,  0.7200,  0.6486,  3.9469, 18.7908,\n",
      "         4.7673,  0.1967,  1.9683,  0.4315,  2.6775,  0.8621,  0.2277,  1.5656,\n",
      "         0.9317, 12.1434, 11.5281], grad_fn=<SelectBackward0>) torch.Size([228146, 27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0607, 0.0100, 0.0123,  ..., 0.0118, 0.1537, 0.1459],\n",
       "        [0.0290, 0.0796, 0.0248,  ..., 0.0118, 0.0022, 0.0472],\n",
       "        [0.0312, 0.0737, 0.0484,  ..., 0.1204, 0.0469, 0.0126],\n",
       "        ...,\n",
       "        [0.0301, 0.0080, 0.0090,  ..., 0.0125, 0.0531, 0.0111],\n",
       "        [0.0634, 0.0270, 0.0101,  ..., 0.0833, 0.0175, 0.0517],\n",
       "        [0.0308, 0.0113, 0.0178,  ..., 0.0190, 0.0116, 0.0562]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ parameters      # 228146,27 X 27 , 27 \n",
    "counts = logits.exp()\n",
    "print(logits[0,:],logits.shape)\n",
    "print(counts[0,:], counts.shape)\n",
    "# now we need to normalize the counts\n",
    "prob = counts / counts.sum(1,keepdim=True)      # probability of next character\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5c468364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7590, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(num),ys].log().mean() \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "243d7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.grad=None\n",
    "loss.backward()\n",
    "parameters.data -= 50*parameters.grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca6ad1",
   "metadata": {},
   "source": [
    "### Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "79f78791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(epoch):\n",
    "    for i in range(epoch):\n",
    "        logits = xenc @ parameters      # 228146,27 X 27 , 27 \n",
    "        counts = logits.exp()\n",
    "        prob = counts / counts.sum(1,keepdim=True)  \n",
    "        loss = -prob[torch.arange(num),ys].log().mean() + 0.1 * (parameters**2).mean() \n",
    "        if i % 10==0:\n",
    "            print(i , loss)    \n",
    "        parameters.grad=None\n",
    "        loss.backward()\n",
    "        parameters.data -= 50*parameters.grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d6f5e4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(3.8556, grad_fn=<AddBackward0>)\n",
      "10 tensor(2.7522, grad_fn=<AddBackward0>)\n",
      "20 tensor(2.6485, grad_fn=<AddBackward0>)\n",
      "30 tensor(2.6163, grad_fn=<AddBackward0>)\n",
      "40 tensor(2.6027, grad_fn=<AddBackward0>)\n",
      "50 tensor(2.5960, grad_fn=<AddBackward0>)\n",
      "60 tensor(2.5923, grad_fn=<AddBackward0>)\n",
      "70 tensor(2.5902, grad_fn=<AddBackward0>)\n",
      "80 tensor(2.5889, grad_fn=<AddBackward0>)\n",
      "90 tensor(2.5881, grad_fn=<AddBackward0>)\n",
      "100 tensor(2.5875, grad_fn=<AddBackward0>)\n",
      "110 tensor(2.5872, grad_fn=<AddBackward0>)\n",
      "120 tensor(2.5869, grad_fn=<AddBackward0>)\n",
      "130 tensor(2.5868, grad_fn=<AddBackward0>)\n",
      "140 tensor(2.5866, grad_fn=<AddBackward0>)\n",
      "150 tensor(2.5866, grad_fn=<AddBackward0>)\n",
      "160 tensor(2.5865, grad_fn=<AddBackward0>)\n",
      "170 tensor(2.5865, grad_fn=<AddBackward0>)\n",
      "180 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "190 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "200 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "210 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "220 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "230 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "240 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "250 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "260 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "270 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "280 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "290 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "300 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "310 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "320 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "330 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "340 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "350 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "360 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "370 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "380 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "390 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "400 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "410 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "420 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "430 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "440 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "450 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "460 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "470 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "480 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "490 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "500 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "510 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "520 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "530 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "540 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "550 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "560 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "570 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "580 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "590 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "600 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "610 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "620 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "630 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "640 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "650 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "660 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "670 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "680 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "690 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "700 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "710 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "720 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "730 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "740 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "750 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "760 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "770 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "780 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "790 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "800 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "810 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "820 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "830 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "840 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "850 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "860 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "870 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "880 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "890 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "900 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "910 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "920 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "930 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "940 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "950 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "960 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "970 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "980 tensor(2.5864, grad_fn=<AddBackward0>)\n",
      "990 tensor(2.5864, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "GD(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b57ab2",
   "metadata": {},
   "source": [
    "### Predict name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "271dbce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexze.\n",
      "momakurailezityha.\n",
      "konimittain.\n",
      "llayn.\n",
      "ka.\n",
      "da.\n",
      "staiyaubjalerigotai.\n",
      "moziellavugie.\n",
      "teda.\n",
      "ka.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "    ix = 0\n",
    "    name = []\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]),num_classes=27).float()\n",
    "\n",
    "        logits = xenc @ parameters\n",
    "\n",
    "        count = logits.exp()\n",
    "        prob = count/count.sum(dim=1,keepdim=True)\n",
    "\n",
    "        ix = torch.multinomial(prob,num_samples=1,replacement=True,generator=g).item()\n",
    "        name.append(itos[ix])\n",
    "        if itos[ix]==\".\":\n",
    "            break\n",
    "    print(\"\".join(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba51c19c",
   "metadata": {},
   "source": [
    "### Predicted names of this model is equal to the predicted name of statistical model\n",
    "cexze.<br>\n",
    "momasurailezitynn.<br>\n",
    "konimittain.<br>\n",
    "llayn.<br>\n",
    "ka.<br>\n",
    "da.<br>\n",
    "staiyaubrtthrigotai.<br>\n",
    "moliellavo.<br>\n",
    "ke.<br>\n",
    "teda.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ff156",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
